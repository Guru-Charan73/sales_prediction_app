{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be6b25a0-2d6c-4377-90d9-47bd08a735b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b3b7b4-43c2-4ed4-8fce-a7fa228c8c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\280384\\AppData\\Local\\Temp\\ipykernel_21524\\343595678.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined['Item_Fat_Content'].replace({'low fat': 'Low Fat', 'LF': 'Low Fat', 'reg': 'Regular'}, inplace=True)\n",
      "C:\\Users\\280384\\AppData\\Local\\Temp\\ipykernel_21524\\343595678.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined['Item_Weight'].fillna(combined['Item_Weight'].mean(), inplace=True)\n",
      "C:\\Users\\280384\\AppData\\Local\\Temp\\ipykernel_21524\\343595678.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined['Outlet_Size'].fillna(combined['Outlet_Size'].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model Evaluation on Actual Test Data:\n",
      "R² Score: 0.9390\n",
      "MAE: 242.68\n",
      "RMSE: 352.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Step 1: Load data\n",
    "train_df = pd.read_csv(\"Train.csv\")\n",
    "test_df_original = pd.read_csv(\"Test.csv\")  # Keep original for final output\n",
    "submission_df = pd.read_csv(\"Submission.csv\")  # contains actuals\n",
    "\n",
    "# Step 2: Merge actual sales with test data for training/evaluation\n",
    "test_df = pd.merge(test_df_original.copy(), submission_df[['Item_Identifier', 'Outlet_Identifier', 'Item_Outlet_Sales']],\n",
    "                   on=['Item_Identifier', 'Outlet_Identifier'])\n",
    "\n",
    "# Step 3: Combine for preprocessing\n",
    "train_df['source'] = 'train'\n",
    "test_df['source'] = 'test'\n",
    "combined = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Step 4: Data cleaning\n",
    "combined['Item_Fat_Content'].replace({'low fat': 'Low Fat', 'LF': 'Low Fat', 'reg': 'Regular'}, inplace=True)\n",
    "combined['Item_Weight'].fillna(combined['Item_Weight'].mean(), inplace=True)\n",
    "combined['Outlet_Size'].fillna(combined['Outlet_Size'].mode()[0], inplace=True)\n",
    "\n",
    "# Step 5: Feature engineering\n",
    "combined['Outlet_Age'] = 2025 - combined['Outlet_Establishment_Year']\n",
    "\n",
    "# Step 6: Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "for col in ['Item_Fat_Content', 'Outlet_Size', 'Outlet_Location_Type',\n",
    "            'Outlet_Type', 'Outlet_Identifier', 'Item_Type']:\n",
    "    combined[col] = le.fit_transform(combined[col])\n",
    "\n",
    "# Step 7: Drop unused columns\n",
    "combined.drop(['Item_Identifier', 'Outlet_Establishment_Year'], axis=1, inplace=True)\n",
    "\n",
    "# Step 8: Split back to train and test sets\n",
    "train_processed = combined[combined['source'] == 'train'].drop(columns='source')\n",
    "test_processed = combined[combined['source'] == 'test'].drop(columns='source')\n",
    "\n",
    "X_train = train_processed.drop('Item_Outlet_Sales', axis=1)\n",
    "y_train = train_processed['Item_Outlet_Sales']\n",
    "X_test = test_processed.drop('Item_Outlet_Sales', axis=1)\n",
    "y_test = test_processed['Item_Outlet_Sales']  # from submission file\n",
    "\n",
    "# Step 9: Train model\n",
    "model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 10: Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(f\" Model Evaluation on Actual Test Data:\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "\n",
    "# Step 11: Save predictions\n",
    "# Match actuals from submission file\n",
    "final_output = test_df_original[['Item_Identifier', 'Outlet_Identifier']].copy()\n",
    "final_output = pd.merge(final_output, submission_df, on=['Item_Identifier', 'Outlet_Identifier'])\n",
    "final_output.rename(columns={'Item_Outlet_Sales': 'Actual_Sales'}, inplace=True)\n",
    "final_output['Predicted_Sales'] = y_pred\n",
    "final_output['Error'] = abs(final_output['Actual_Sales'] - final_output['Predicted_Sales'])\n",
    "\n",
    "final_output.to_csv(\"XGBoost_Sales_Predictions_Final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f4edf69-3ca0-4a1a-86fb-d845212f15e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_feature_columns.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'xgb_sales_model.pkl')\n",
    "\n",
    "# Save the feature column order for prediction consistency\n",
    "feature_columns = X_train.columns.tolist()\n",
    "joblib.dump(feature_columns, 'xgb_feature_columns.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb586bd-e4a9-4cc6-afe9-d94fa1308905",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_actual = final_output['Actual_Sales'].mean()\n",
    "mean_error = final_output['Error'].mean()\n",
    "mean_absolute_percentage_error = (mean_error / mean_actual) * 100\n",
    "accuracy = 100 - mean_absolute_percentage_error\n",
    " \n",
    "print(f\"\\nModel Accuracy Metrics:\")\n",
    "print(f\"Mean Actual Sales: {mean_actual:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mean_error:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mean_absolute_percentage_error:.2f}%\")\n",
    "print(f\"Model Accuracy (100 - MAPE): {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f729149-e503-45d4-8def-a0eaa7aae2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2122c7f-142d-4a84-aa66-988ae3dd425d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
